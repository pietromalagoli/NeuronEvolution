{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import graphviz\n",
    "from pprint import pprint\n",
    "\n",
    "# Set the seed for random generations\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -Tpng -O diagraph.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![diagraph.png](./diagraph.txt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a convention, J_ij is the link that goes from node j to node i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I try to create a class for the NN\n",
    "class Network:\n",
    "    \"\"\"\n",
    "    Class for a generic neural network, defined by \n",
    "    - 2 input neurons, 1 output neuron\n",
    "    - S: # of intra neurons.\n",
    "    - Theta: threshold value.\n",
    "    - J: connectivity matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.S = 1      # Initialize with one intra neuron\n",
    "        self.Theta = np.zeros(2+self.S+1)   # I instantiate a threshold value for each neuron, even the input, just for consistency of the indexes\n",
    "        # Define the connectivity matrix J0_ij\n",
    "        J0 = np.ones((2+self.S+1,2+self.S+1)) # Initialized all to one, so all connnected\n",
    "        for j in range(len(J0)):            # First, impose on J0 that the elements on the diagonal must be zero\n",
    "            J0[j,j] = 0.\n",
    "        J0[0,1] = 0.            # Impose on the connectiviy matrix the fact that nuerons on the same layer cannot be connected \n",
    "        J0[1,0] = 0.\n",
    "        for i in range(2, 2 + self.S):\n",
    "            for j in range(2, 2 + self.S):\n",
    "                if i != j:\n",
    "                    J0[i, j] = 0.       \n",
    "        self.J = J0\n",
    "        self.activation = lambda x, theta: 0 if x < theta else 1    # activation function (if x = theta -> returns 1)\n",
    "        self.neurons = np.zeros(2+self.S+1) # container for storing the values of the neurons\n",
    "        self.fitness = 0.\n",
    "        \n",
    "    def initJ(self):            # QUESTO VA POI FATTO MEGLIO\n",
    "        # Define the connectivity matrix J0_ij\n",
    "        J0 = np.ones((2+self.S+1,2+self.S+1)) # Initialized all to one, so all connnected\n",
    "        for j in range(len(J0)):            # First, impose on J0 that the elements on the diagonal must be zero\n",
    "            J0[j,j] = 0.\n",
    "        J0[0,1] = 0.            # Impose on the connectiviy matrix the fact that nuerons on the same layer cannot be connected \n",
    "        J0[1,0] = 0.\n",
    "        for i in range(2, 2 + self.S):\n",
    "            for j in range(2, 2 + self.S):\n",
    "                if i != j:\n",
    "                    J0[i, j] = 0. \n",
    "        return J0\n",
    "    \n",
    "    def generate(self,par:dict):\n",
    "        \"\"\"Generate a random network.\n",
    "\n",
    "        Args:\n",
    "            par (dict, optional): parameters of the generation.\n",
    "        \"\"\"\n",
    "        self.S = par['Sk_range'][np.random.randint(len(par['Sk_range']))]   # Generate S\n",
    "        self.Theta = np.random.uniform(par['Theta_range'][0],par['Theta_range'][1],2+self.S+1) # Generate the set of thresholds, Theta\n",
    "        self.J = self.initJ() * np.random.uniform(par['J_range'][0],par['J_range'][1],(2+self.S+1)**2).reshape((2+self.S+1,2+self.S+1))   # Generate the connectivity matrix, J\n",
    "        self.neurons = np.zeros(2+self.S+1)\n",
    "        \n",
    "    def ff(self,input:list,verb:int=0): # feed-forward\n",
    "        \"\"\"Compute the output of the network by feed-forward, given an input.\n",
    "\n",
    "        Args:\n",
    "            input (list): input to the network. Supported inputs are [0,0];[0,1];[1,0];[1,1].\n",
    "            verb (int,optional): verbosity. If > 0, returns the value of each neuron. Default to 0.\n",
    "\n",
    "        Returns:\n",
    "            output (int): output of the network.\n",
    "        \"\"\"\n",
    "        self.neurons[0:2] = input   # set the value of the first two neurons to the input value\n",
    "        \n",
    "        for neuron in range(1,2+self.S):    # compute the value of the intra neurons by feed forward\n",
    "            self.neurons[neuron] = self.J[neuron,0] * self.neurons[0] + self.J[neuron,1] * self.neurons[1]   # I refer to the lower triangle of the matrix J\n",
    "            self.neurons[neuron] = self.activation(self.neurons[neuron],self.Theta[neuron])     # Activation\n",
    "        \n",
    "        for neuron in range(0,2+self.S):  # compute the value of the ouput\n",
    "            self.neurons[-1] = self.J[-1,neuron] * self.neurons[neuron]     # Add each neuron's weighted contribution to the output\n",
    "        self.neurons[-1] = self.activation(self.neurons[-1],self.Theta[-1])     # activation\n",
    "        output = self.neurons[-1]\n",
    "        if verb > 0:\n",
    "            return self.neurons\n",
    "        return output\n",
    "        \n",
    "    def compute_fitness(self,par:dict):\n",
    "        \"\"\"Compute the output of the network and from that the fitness value \n",
    "            and with that updates the network's fitness value.\n",
    "\n",
    "        Args:\n",
    "            par (dict): parameters of the generation.\n",
    "            \n",
    "        \"\"\"\n",
    "        for i,input in enumerate(par['input_set']):\n",
    "            output = self.ff(input)\n",
    "            squared_dist = (par['target_set'][i] - output)**2     # square distance between network output and target (theoretical) output\n",
    "            squared_cost = (np.sum([0 if np.isclose(j, 0., rtol=1e-3) else 1 for j in self.J.flatten()])/2)**2  # check if the tolerance is good\n",
    "            self.fitness += squared_dist * squared_cost # add to the fitness value of the network\n",
    "        self.fitness / len(par['input_set'])    # normalize over the inputs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model I don't need to define the space grid, I just need to generate the solutions and then execute the algorithm. I just need to make sure that they stay in the range.\n",
    "\n",
    "I try first one loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the set of parameters\n",
    "par = {'Sk_range': [1,2,3,4,5],  # define the possible value for Sk\n",
    "       'Theta_range': [-1,+1],     # define the possible value for Theta\n",
    "       'J_range': [-1,+1],  # define the possible value for J\n",
    "       'N_sol': 20,         # Set the number of solutions\n",
    "       'input_set':[[0,0],[0,1],[1,0],[1,1]],    # Set of inputs\n",
    "       'target_set': [0,1,1,0],    # set of outputs for the XOR gate \n",
    "       'mutation_ratio': 0.7,             # set the ratio of mutated solutions over the whole number of individuals \n",
    "                                          # that have to be generate after a selection. Who is not mutated is random \n",
    "       'S_mutation_radius': 1,\n",
    "       'Theta_mutations_radius': 1/20,\n",
    "       'J_mutations_radius': 1/20}                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'J': array([[-0.        ,  0.        , -0.25215765, -0.69005329,  0.78468746,\n",
      "        -0.94642055],\n",
      "       [-0.        , -0.        ,  0.61457742,  0.25418865,  0.81584979,\n",
      "         0.11279461],\n",
      "       [ 0.6798385 , -0.89902409,  0.        ,  0.        , -0.        ,\n",
      "         0.38189585],\n",
      "       [-0.74137086,  0.6653728 , -0.        ,  0.        ,  0.        ,\n",
      "        -0.27258632],\n",
      "       [ 0.58994114,  0.3969623 ,  0.        ,  0.        ,  0.        ,\n",
      "         0.81991544],\n",
      "       [ 0.94982718,  0.31223918,  0.62397913, -0.79451202, -0.52494309,\n",
      "        -0.        ]]),\n",
      " 'S': 3,\n",
      " 'Theta': array([ 0.78030943, -0.73858541, -0.92048101,  0.65287226,  0.06415584,\n",
      "        0.91261996]),\n",
      " 'activation': <function Network.__init__.<locals>.<lambda> at 0x7f3127b77f60>,\n",
      " 'fitness': 0.0,\n",
      " 'neurons': array([0., 0., 0., 0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "a = [0,0]\n",
    "a = par['input_set'][3]\n",
    "n = Network()\n",
    "n.generate(par)\n",
    "pprint(vars(n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 4 3 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 3, 5])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,4,5])\n",
    "a = np.insert(a,obj=-1,values=3)\n",
    "print(a)\n",
    "np.delete(a,[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(1,5,5,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4096696115.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 13\u001b[0;36m\u001b[0m\n\u001b[0;31m    solutions[solution].\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Generate the solutions\n",
    "solutions = []\n",
    "for _ in range(par['N_sol']):\n",
    "    # Generate a solution\n",
    "    n = Network()\n",
    "    n = n.generate(par)\n",
    "    solutions.append(n)\n",
    "\n",
    "# Compute the fitness value for each solution\n",
    "fitness_values = []\n",
    "for solution in range(par['N_sol']):\n",
    "    solutions[solution].compute_fitness(par)\n",
    "    fitness_values.append(solutions[solution].fitness)\n",
    "    \n",
    "# Compute the mean fitness\n",
    "mean_fit = np.sum(fitness_values) / par['N_sol']    # Here I don't have to divide also by 4, \n",
    "                                                    # because I've already done it in the compute_fitness method\n",
    "\n",
    "# discard elements in sol whose fitness value is below average\n",
    "solutions = [s.fitness >= mean_fit for s in solutions]\n",
    "\n",
    "# Compute the number of discarded elements, m\n",
    "m = par['N_sol'] - len(solutions)\n",
    "\n",
    "# Extract the parents between the survivors (here we can either take them random or take the fittest survivors)\n",
    "# randomly\n",
    "n_parents = np.floor(par['mutation_ratio'] * m)\n",
    "parents_idx = np.random.randint(0,len(solutions),n_parents)\n",
    "parents = solutions[parents_idx]\n",
    "\n",
    "# Firstly, instantiate the offsprings as copies of the parents\n",
    "offspring = parents\n",
    "\n",
    "# Now, mutate S first\n",
    "for child in offspring:\n",
    "    sign_idx = np.random.randint(2)     # extract uniformly 0 or 1 for choosing the sign of the mutation\n",
    "    sign_array = [-1,+1]                # this is used to apply the sign\n",
    "    child.S += sign_array[sign_idx] * par['S_mutation_radius']\n",
    "    # Check the boundary conditions for S\n",
    "    if child.S < min(par['Sk_range']):\n",
    "        child.S = min(par['Sk_range'])\n",
    "    if child.S > max(par['Sk_range']):\n",
    "        child.S = max(par['Sk_range'])\n",
    "\n",
    "# Now mutate the thresholds - if S decreased, you mutate only the remaining neurons, else, you randomly generate the new theta(s)\n",
    "for i,child in enumerate(offspring):\n",
    "    # compute the difference between the orignal S and the mutated one\n",
    "    deltaS = child.S - parents[i].S\n",
    "    if deltaS > 0:\n",
    "        new_thetas = np.random.uniform(par['Theta_range'][0],par['Theta_range'][1],deltaS)\n",
    "        child.Theta = np.insert(child.Theta,obj=-1,values=new_thetas)   # add the newly generated thetas before the output neuron\n",
    "    else:\n",
    "        np.delete(child.Theta,np.linspace(2+parents[i].S,2+child.S,deltaS)) # delete the theta values of the deleted neurons\n",
    "\n",
    "    # mutate theta (I mutate also the newly generated thetas)\n",
    "    mutationTheta = np.random.uniform(par['Theta_range'][0]*par['Theta_mutation_radius'], \n",
    "                                  par['Theta_range'][1]*par['Theta_mutation_radius'], len(child.Theta))   # generate the mutation radius \n",
    "    child.Theta += mutationTheta\n",
    "    # Check the boundary conditions for Theta\n",
    "    for theta in child.Theta:\n",
    "        if theta < min(par['Theta_range']):\n",
    "            theta = min(par['Theta_range'])\n",
    "        if theta > max(par['Theta_range']):\n",
    "            theta = max(par['Theta_range'])\n",
    "            \n",
    "# Mutate J\n",
    "for i,child in enumerate(offspring):\n",
    "    # compute the difference between the original S and the mutated one\n",
    "    deltaS = child.S - parents[i].S\n",
    "    J0 = child.initJ()     # I utilize the method initJ() to create a new J given the new S\n",
    "    if deltaS > 0:\n",
    "        for _ in range(deltaS):\n",
    "            j = np.random.uniform(par['J_range'][0],par['J_range'][1])  # generate a random value to be given to the new links\n",
    "            child.J = np.insert(child.J,obj=-1,values=j,axis=0)    # insert a row of 1s (axis 0)\n",
    "            child.J = np.insert(child.J,obj=-1,values=j,axis=1)    # insert a column of 1s (axis 1)\n",
    "    else:\n",
    "        for _ in range(deltaS):\n",
    "            np.delete(child.J,np.linspace(2+parents[i].S,2+child.S,deltaS,axis=0)) # delete the J values of the deleted neurons on axis 0\n",
    "            np.delete(child.J,np.linspace(2+parents[i].S,2+child.S,deltaS,axis=1)) # delete the J values of the deleted neurons on axis 1        \n",
    "    # multiplicate with J0 to set to 0 where necessary by the conditions\n",
    "    child.J *= J0\n",
    "    # mutate (I mutate also the newly generated thetas)\n",
    "    mutationJ = np.random.uniform(par['J_range'][0]*par['J_mutation_radius'], \n",
    "                                  par['J_range'][1]*par['J_mutation_radius'], len(child.J)**2)   # generate the mutation radius \n",
    "    # Check the boundary conditions for J\n",
    "    for j in child.J:\n",
    "        if j < min(par['J_range']):\n",
    "            j = min(par['J_range'])\n",
    "        if j > max(par['J_range']):\n",
    "            j = max(par['J_range'])\n",
    "            \n",
    "# Fix also the other attributes\n",
    "for i,child in enumerate(offspring):\n",
    "    # compute the difference between the orignal S and the mutated one\n",
    "    deltaS = child.S - parents[i].S\n",
    "    if deltaS > 0:\n",
    "        child.neurons = np.insert(child.neurons,obj=-1,values=0.5)      # i set the new neurons to 0.5\n",
    "    else:\n",
    "        np.delete(child.neurons,2+child.S,deltaS)   # delete the eliminated neurons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
