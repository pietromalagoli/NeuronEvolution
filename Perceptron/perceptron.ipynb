{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import graphviz\n",
    "from pprint import pprint\n",
    "import copy\n",
    "\n",
    "import aux\n",
    "\n",
    "# Set the seed for random generations\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dot -Tpng -O diagraph.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![diagraph.png](./diagraph.txt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a convention, J_ij is the link that goes from node j to node i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I try to create a class for the NN\n",
    "class Network:\n",
    "    \"\"\"\n",
    "    Class for a generic neural network, defined by \n",
    "    - 2 input neurons, 1 output neuron\n",
    "    - S: # of intra neurons.\n",
    "    - Theta: threshold value.\n",
    "    - J: connectivity matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.S = 1      # Initialize with one intra neuron\n",
    "        self.Theta = np.zeros(2+self.S+1)   # I instantiate a threshold value for each neuron, even the input, just for consistency of the indexes\n",
    "        # Define the connectivity matrix J0_ij\n",
    "        J0 = np.ones((2+self.S+1,2+self.S+1)) # Initialized all to one, so all connnected\n",
    "        for j in range(len(J0)):            # First, impose on J0 that the elements on the diagonal must be zero\n",
    "            J0[j,j] = 0.\n",
    "        J0[0,1] = 0.            # Impose on the connectiviy matrix the fact that nuerons on the same layer cannot be connected \n",
    "        J0[1,0] = 0.\n",
    "        for i in range(2, 2 + self.S):\n",
    "            for j in range(2, 2 + self.S):\n",
    "                if i != j:\n",
    "                    J0[i, j] = 0.       \n",
    "        self.J = J0\n",
    "        self.activation = lambda x, theta: 0 if x < theta else 1    # activation function (if x = theta -> returns 1)\n",
    "        self.neurons = np.zeros(2+self.S+1) # container for storing the values of the neurons\n",
    "        self.fitness = None     # Initialize it to None for avoiding recomputation\n",
    "        \n",
    "    def initJ(self):            # QUESTO VA POI FATTO MEGLIO\n",
    "        # Define the connectivity matrix J0_ij\n",
    "        J0 = np.ones((2+self.S+1,2+self.S+1)) # Initialized all to one, so all connnected\n",
    "        for j in range(len(J0)):            # First, impose on J0 that the elements on the diagonal must be zero\n",
    "            J0[j,j] = 0.\n",
    "        J0[0,1] = 0.            # Impose on the connectiviy matrix the fact that nuerons on the same layer cannot be connected \n",
    "        J0[1,0] = 0.\n",
    "        for i in range(2, 2 + self.S):\n",
    "            for j in range(2, 2 + self.S):\n",
    "                if i != j:\n",
    "                    J0[i, j] = 0. \n",
    "        return J0\n",
    "    \n",
    "    def generate(self,par:dict):\n",
    "        \"\"\"Generate a random network.\n",
    "\n",
    "        Args:\n",
    "            par (dict, optional): parameters of the generation.\n",
    "        \"\"\"\n",
    "        self.S = par['Sk_range'][np.random.randint(len(par['Sk_range']))]   # Generate S\n",
    "        self.Theta = np.random.uniform(par['Theta_range'][0],par['Theta_range'][1],2+self.S+1) # Generate the set of thresholds, Theta\n",
    "        self.J = self.initJ() * np.random.uniform(par['J_range'][0],par['J_range'][1],(2+self.S+1)**2).reshape((2+self.S+1,2+self.S+1))   # Generate the connectivity matrix, J\n",
    "        self.neurons = np.zeros(2+self.S+1)     # Initialize the values of the neurons (the lenght of this array depends on S)\n",
    "        self.compute_fitness(par)               # Already compute the fitness value of the network\n",
    "        \n",
    "    def ff(self,input:list,verb:int=0): # feed-forward\n",
    "        \"\"\"Compute the output of the network by feed-forward, given an input.\n",
    "\n",
    "        Args:\n",
    "            input (list): input to the network. Supported inputs are [0,0];[0,1];[1,0];[1,1].\n",
    "            verb (int,optional): verbosity. If > 0, returns the value of each neuron. Default to 0.\n",
    "\n",
    "        Returns:\n",
    "            output (int): output of the network.\n",
    "        \"\"\"\n",
    "        self.neurons[0:2] = input   # set the value of the first two neurons to the input value\n",
    "        \n",
    "        for neuron in range(1,2+self.S):    # compute the value of the intra neurons by feed forward\n",
    "            self.neurons[neuron] = self.J[neuron,0] * self.neurons[0] + self.J[neuron,1] * self.neurons[1]   # I refer to the lower triangle of the matrix J\n",
    "            self.neurons[neuron] = self.activation(self.neurons[neuron],self.Theta[neuron])     # Activation\n",
    "        \n",
    "        for neuron in range(0,2+self.S):  # compute the value of the ouput\n",
    "            self.neurons[-1] = self.J[-1,neuron] * self.neurons[neuron]     # Add each neuron's weighted contribution to the output\n",
    "        self.neurons[-1] = self.activation(self.neurons[-1],self.Theta[-1])     # activation\n",
    "        output = self.neurons[-1]\n",
    "        if verb > 0:\n",
    "            return self.neurons\n",
    "        return output\n",
    "        \n",
    "    def compute_fitness(self,par:dict):\n",
    "        \"\"\"Compute the output of the network and from that the fitness value \n",
    "            and with that updates the network's fitness value.\n",
    "\n",
    "        Args:\n",
    "            par (dict): parameters of the generation.\n",
    "            \n",
    "        \"\"\"\n",
    "        if self.fitness == None:        # I need this check, bc otherwise I risk of adding fitness over fitness\n",
    "            self.fitness = 0.           # This is to avoid type conflict and to make sure that I'm not computing the fitness of a network that already has it\n",
    "            for i,input in enumerate(par['input_set']):\n",
    "                output = self.ff(input)\n",
    "                squared_dist = (par['target_set'][i] - output)**2     # square distance between network output and target (theoretical) output\n",
    "                squared_cost = (np.sum([0 if np.isclose(j, 0., rtol=1e-3) else 1 for j in self.J.flatten()])/2)**2  # check if the tolerance is good\n",
    "                self.fitness += squared_dist * squared_cost # add to the fitness value of the network\n",
    "            self.fitness /= len(par['input_set'])    # normalize over the inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model I don't need to define the space grid, I just need to generate the solutions and then execute the algorithm. I just need to make sure that they stay in the range.\n",
    "\n",
    "I try first one loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the set of parameters\n",
    "par = {'Sk_range': [1,2,3,4,5],  # define the possible value for Sk\n",
    "       'Theta_range': [-1,+1],     # define the possible value for Theta\n",
    "       'J_range': [-1,+1],  # define the possible value for J\n",
    "       'input_set':[[0,0],[0,1],[1,0],[1,1]],    # Set of inputs\n",
    "       'target_set': [0,1,1,0],    # set of outputs for the XOR gate \n",
    "       'mutation_ratio': 0.7,             # set the ratio of mutated solutions over the whole number of individuals that have to be generate after a selection. Who is not mutated is random \n",
    "       'S_mutation_radius': 1,\n",
    "       'Theta_mutation_radius': 1/20,\n",
    "       'J_mutation_radius': 1/20,\n",
    "       'N_sol': 20,                       # Set the number of solutions \n",
    "       'n_iter': 100}                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.          0.         -0.25215765 -0.69005329  0.78468746 -0.94642055]\n",
      "\n",
      "[-0.         -0.          0.61457742  0.25418865  0.81584979  0.11279461]\n",
      "\n",
      "[ 0.6798385  -0.89902409  0.          0.         -0.          0.38189585]\n",
      "\n",
      "[-0.74137086  0.6653728  -0.          0.          0.         -0.27258632]\n",
      "\n",
      "[0.58994114 0.3969623  0.         0.         0.         0.81991544]\n",
      "\n",
      "[ 0.94982718  0.31223918  0.62397913 -0.79451202 -0.52494309 -0.        ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = Network()\n",
    "n.generate(par)\n",
    "for j in n.J:\n",
    "    print(f'{j}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolution(par:dict):\n",
    "    # Generate the solutions\n",
    "    solutions = []\n",
    "    for _ in range(par['N_sol']):\n",
    "        # Generate a solution\n",
    "        n = Network()\n",
    "        n.generate(par)     # already computes also the fitness value\n",
    "        solutions.append(n)\n",
    "    solutions = np.array(solutions)\n",
    "    # Initiate some container for statistic\n",
    "    mean_values = []\n",
    "    S_values = []\n",
    "    \n",
    "    ##  EVOLUTION\n",
    "    for iter in range(par['n_iter']):\n",
    "        print(f'Iteration #{iter}...')\n",
    "        # Compute the mean fitness\n",
    "        mean_fit = np.sum([sol.fitness for sol in solutions]) / par['N_sol']    # Here I don't have to divide also by 4, because I've already done it in the compute_fitness method\n",
    "        # Discard elements in sol whose fitness value is below average \n",
    "        solutions = np.array([sol for sol in solutions if sol.fitness >= mean_fit])\n",
    "        # Compute the number of discarded elements, m\n",
    "        m = par['N_sol'] - len(solutions)\n",
    "        # Extract the parents between the survivors (here we can either take them random or take the fittest survivors)\n",
    "        n_parents = int(np.floor(par['mutation_ratio'] * m))\n",
    "        parents_idx = np.random.randint(low=0,high=int(len(solutions)),size=n_parents,dtype=int)\n",
    "        parents = solutions[parents_idx]\n",
    "        # Firstly, instantiate the offsprings as copies of the parents\n",
    "        offspring = copy.deepcopy(parents)      # I must use copy.deepcopy because otherwise I modify both objects when I modify one\n",
    "        \n",
    "        ## MUTATION\n",
    "        # Now, mutate S first\n",
    "        for i,child in enumerate(offspring):\n",
    "            sign_idx = np.random.randint(2)     # extract uniformly 0 or 1 for choosing the sign of the mutation\n",
    "            sign_array = [-1,+1]                # this is used to apply the sign\n",
    "            child.S += sign_array[sign_idx] * par['S_mutation_radius']\n",
    "            # Check the boundary conditions for S\n",
    "            if child.S < min(par['Sk_range']):\n",
    "                child.S = min(par['Sk_range'])\n",
    "            if child.S > max(par['Sk_range']):\n",
    "                child.S = max(par['Sk_range'])\n",
    "            # Now mutate the thresholds - if S decreased, you mutate only the remaining neurons, else, you randomly generate the new theta(s)\n",
    "            # compute the difference between the orignal S and the mutated one\n",
    "            deltaS = child.S - parents[i].S\n",
    "            print(f'DeltaS:{deltaS}')\n",
    "            if deltaS > 0:\n",
    "                new_thetas = np.random.uniform(par['Theta_range'][0],par['Theta_range'][1],deltaS)\n",
    "                child.Theta = np.insert(child.Theta,obj=-1,values=new_thetas)   # add the newly generated thetas before the output neuron\n",
    "            else:\n",
    "                for _ in range(np.abs(deltaS)):\n",
    "                    np.delete(child.Theta,obj=-1) # delete the theta values of the deleted neurons\n",
    "            # mutate theta (I mutate also the newly generated thetas)\n",
    "            mutationTheta = np.random.uniform(par['Theta_range'][0]*par['Theta_mutation_radius'], \n",
    "                                        par['Theta_range'][1]*par['Theta_mutation_radius'], len(child.Theta))   # generate the mutation radius \n",
    "            child.Theta += mutationTheta\n",
    "            # Check the boundary conditions for Theta\n",
    "            for theta in child.Theta:\n",
    "                if theta < min(par['Theta_range']):\n",
    "                    theta = min(par['Theta_range'])\n",
    "                if theta > max(par['Theta_range']):\n",
    "                    theta = max(par['Theta_range'])     \n",
    "            # Mutate J\n",
    "            J0 = child.initJ()     # I utilize the method initJ() to create a new J given the new S\n",
    "            print(deltaS < 0)\n",
    "            if deltaS > 0:\n",
    "                for _ in range(deltaS):\n",
    "                    j = np.random.uniform(par['J_range'][0],par['J_range'][1])  # generate a random value to be given to the new links\n",
    "                    child.J = np.insert(child.J,obj=-1,values=j,axis=0)    # insert a row of 1s (axis 0)\n",
    "                    child.J = np.insert(child.J,obj=-1,values=j,axis=1)    # insert a column of 1s (axis 1)\n",
    "            else:\n",
    "                for _ in range(np.abs(deltaS)):\n",
    "                    np.delete(child.J,obj=-1,axis=0) # delete the J values of the deleted neurons on axis 0\n",
    "                    print(child.J)\n",
    "                    np.delete(child.J,obj=-1,axis=1) # delete the J values of the deleted neurons on axis 1    \n",
    "                    print(child.J)    \n",
    "            # mutate (I mutate also the newly generated thetas)\n",
    "            mutationJ = np.random.uniform(par['J_range'][0]*par['J_mutation_radius'], \n",
    "                                        par['J_range'][1]*par['J_mutation_radius'], len(child.J)**2).reshape(child.J.shape)   # generate the mutation radius \n",
    "            # Apply the mutation\n",
    "            child.J += mutationJ\n",
    "            # multiplicate with J0 to set to 0 where necessary by the conditions\n",
    "            print(f'J:{child.J.shape}')\n",
    "            print(f'J0:{J0.shape}')           \n",
    "            child.J *= J0\n",
    "            # Check the boundary conditions for J\n",
    "            for row in child.J:\n",
    "                for j in row:\n",
    "                    if j < min(par['J_range']):\n",
    "                        j = min(par['J_range'])\n",
    "                    if j > max(par['J_range']):\n",
    "                        j = max(par['J_range'])        \n",
    "            # Fix also the other attributes\n",
    "            if deltaS > 0:\n",
    "                child.neurons = np.insert(child.neurons,obj=-1,values=0.5)      # i set the new intra neurons to 0.5\n",
    "            else:\n",
    "                np.delete(child.neurons,2+child.S,deltaS)   # delete the eliminated intra neurons\n",
    "                \n",
    "            # Already compute the fitness value of the network\n",
    "            child.fitness = None            # I have to first set it to None beacuse child inherits self.fitness from the parent\n",
    "            child.compute_fitness(par)      # Here I have to do it explicitly because I'm not generating the Network object through Network.generate()       \n",
    "        # Add the offsprings generated by mutation to the survived solutions\n",
    "        solutions = np.concatenate([solutions,offspring])\n",
    "        # Randomly generate the remaining individuals (population must be constant)\n",
    "        n_generation = m - n_parents\n",
    "        generated = []\n",
    "        for _ in range(n_generation):\n",
    "            # Generate a solution\n",
    "            n = Network()\n",
    "            n = n.generate(par)             # already with computed fitness\n",
    "            generated.append(n)\n",
    "        generated = np.array(generated)     # transform it to a np.ndarray\n",
    "        # Add the randomly generated solutions to the other solutions\n",
    "        solutions = np.concatenate([solutions,generated])\n",
    "        # Add a check for conservation of population\n",
    "        if len(solutions) != par['N_sol']:\n",
    "            msg = f'The solutions population was not conserved. Expected {par['N_sol']}, but instead got {len(solutions)}.'\n",
    "            aux.checkpoint(True,msg=msg,stop=True)    \n",
    "        # Shuffle the order of the solutions for good measure\n",
    "        np.random.shuffle(solutions)\n",
    "        # Statistic \n",
    "        meanS = np.mean(solutions.S)\n",
    "        mean_values.append(mean_fit)\n",
    "        S_values.append(meanS)\n",
    "    return solutions, mean_values, meanS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #0...\n",
      "DeltaS:1\n",
      "False\n",
      "J:(7, 7)\n",
      "J0:(7, 7)\n",
      "DeltaS:1\n",
      "False\n",
      "J:(7, 7)\n",
      "J0:(7, 7)\n",
      "DeltaS:1\n",
      "False\n",
      "J:(7, 7)\n",
      "J0:(7, 7)\n",
      "DeltaS:0\n",
      "False\n",
      "J:(8, 8)\n",
      "J0:(8, 8)\n",
      "DeltaS:1\n",
      "False\n",
      "J:(8, 8)\n",
      "J0:(8, 8)\n",
      "DeltaS:-1\n",
      "True\n",
      "[[ 0.00000000e+00  0.00000000e+00 -6.48977854e-01  2.10775692e-02\n",
      "   5.69191679e-04  7.85535264e-01 -2.34634585e-01  3.25727674e-01]\n",
      " [-0.00000000e+00  0.00000000e+00 -2.62429415e-01  8.96057273e-01\n",
      "  -3.05549564e-01  3.67786398e-01  6.49269763e-01 -2.74940115e-02]\n",
      " [ 9.68351743e-01  2.07628076e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -7.47689234e-01]\n",
      " [ 9.53201235e-01 -5.41788688e-01 -0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -3.80231248e-01]\n",
      " [-4.67222228e-01  1.86862302e-01 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  9.77282835e-01]\n",
      " [-1.31897294e-01  6.56378552e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -0.00000000e+00 -0.00000000e+00  7.19102461e-01]\n",
      " [ 6.20039222e-01  6.73087769e-01 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00  0.00000000e+00  0.00000000e+00  6.55009725e-01]\n",
      " [-8.47784780e-01  1.06275889e-01  9.58809195e-02  8.10887196e-01\n",
      "  -2.61022651e-01  8.02325284e-01 -7.18737950e-01 -0.00000000e+00]]\n",
      "[[ 0.00000000e+00  0.00000000e+00 -6.48977854e-01  2.10775692e-02\n",
      "   5.69191679e-04  7.85535264e-01 -2.34634585e-01  3.25727674e-01]\n",
      " [-0.00000000e+00  0.00000000e+00 -2.62429415e-01  8.96057273e-01\n",
      "  -3.05549564e-01  3.67786398e-01  6.49269763e-01 -2.74940115e-02]\n",
      " [ 9.68351743e-01  2.07628076e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -7.47689234e-01]\n",
      " [ 9.53201235e-01 -5.41788688e-01 -0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -3.80231248e-01]\n",
      " [-4.67222228e-01  1.86862302e-01 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00  9.77282835e-01]\n",
      " [-1.31897294e-01  6.56378552e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -0.00000000e+00 -0.00000000e+00  7.19102461e-01]\n",
      " [ 6.20039222e-01  6.73087769e-01 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00  0.00000000e+00  0.00000000e+00  6.55009725e-01]\n",
      " [-8.47784780e-01  1.06275889e-01  9.58809195e-02  8.10887196e-01\n",
      "  -2.61022651e-01  8.02325284e-01 -7.18737950e-01 -0.00000000e+00]]\n",
      "J:(8, 8)\n",
      "J0:(7, 7)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8,8) (7,7) (8,8) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sol, mean_values, meanS \u001b[38;5;241m=\u001b[39m \u001b[43mevolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpar\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 83\u001b[0m, in \u001b[0;36mevolution\u001b[0;34m(par)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJ:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchild\u001b[38;5;241m.\u001b[39mJ\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJ0:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mJ0\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)           \n\u001b[0;32m---> 83\u001b[0m \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJ\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mJ0\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Check the boundary conditions for J\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m child\u001b[38;5;241m.\u001b[39mJ:\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (8,8) (7,7) (8,8) "
     ]
    }
   ],
   "source": [
    "sol, mean_values, meanS = evolution(par)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
